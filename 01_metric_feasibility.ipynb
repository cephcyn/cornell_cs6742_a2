{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb6573-cbcf-4cf2-8fca-79d7f75a2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Display outputs from all lines when they exist\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bbce8-dbea-4d5e-b49c-4dcdfee7a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63837d43-8017-4c3e-92dd-bd3ecbf0e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CSV\n",
    "posts_2018_df = pd.read_csv(\"2018_posts.csv\")\n",
    "comms_2018_df = pd.read_csv(\"2018_comments.csv\")\n",
    "posts_2019_df = pd.read_csv(\"2019_posts.csv\")\n",
    "comms_2019_df = pd.read_csv(\"2019_comments_partial.csv\")\n",
    "\n",
    "# Read from PKL\n",
    "# posts_2018_df = pd.read_pickle(\"2018_posts.pkl\")\n",
    "# comms_2018_df = pd.read_pickle(\"2018_comments.pkl\")\n",
    "# posts_2019_df = pd.read_pickle(\"2019_posts.pkl\")\n",
    "# comms_2019_df = pd.read_pickle(\"2019_comments_partial.pkl\")\n",
    "\n",
    "print(posts_2018_df.shape, comms_2018_df.shape)\n",
    "print(posts_2019_df.shape, comms_2019_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a34c9-0280-4389-a841-8a1bc744a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = posts_2018_df.append(posts_2019_df).reset_index(drop=True)\n",
    "comms_df = comms_2018_df.append(comms_2019_df).reset_index(drop=True)\n",
    "\n",
    "print(posts_df.shape)\n",
    "print(comms_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb2ad4-0f1c-4eed-8f03-b757d8932282",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df[posts_df['id']=='9zgc4m'] # the ID of the first bot implementation announcement\n",
    "\n",
    "# only include posts AFTER that announcement cutoff\n",
    "posts_df = posts_df[posts_df['created_utc'] > posts_df[posts_df['id']=='9zgc4m'].iloc[0]['created_utc']].reset_index(drop=True)\n",
    "print(posts_df.shape)\n",
    "# and cut down the comments df to only include data for posts within that dataset, while we're at it\n",
    "comms_df = comms_df[comms_df['link_id'].apply(lambda x: str(x)[3:]).isin(posts_df['id'])].reset_index(drop=True)\n",
    "print(comms_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c637658-93e3-472f-a819-5c14534dcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of users that should always be filtered out from the counts\n",
    "restricted_users_list = ['AutoModerator', 'Judgement_Bot_AITA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa9a00-52f6-40ea-8e60-5ab554dbb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df[:2]\n",
    "comms_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34475ef2-02c1-49b2-82ef-40092e7e8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the judgement that a specific comment gives, if any\n",
    "def comment_judgement(comms_df):\n",
    "    # Judgement tags are in {'NTA', 'YTA', 'NAH', 'ESH', 'INFO', 'SHP' (not formal after a certain point but still commonly quoted)}\n",
    "    potential_tags = ['NTA', 'YTA', 'NAH', 'ESH', 'INFO', 'SHP']\n",
    "    tags = {'id':[], 'judgement_tag':[]}\n",
    "    for _, comment in comms_df.iterrows():\n",
    "        judgements = []\n",
    "        for ptag in potential_tags:\n",
    "            if (isinstance(comment['body'], str)) and (ptag in comment['body']):\n",
    "                judgements.append(ptag)\n",
    "        tags['id'].append(comment['id'])\n",
    "        if len(judgements)==1:\n",
    "            tags['judgement_tag'].append(judgements[0])\n",
    "        else:\n",
    "            tags['judgement_tag'].append(None)\n",
    "    return pd.DataFrame(tags)\n",
    "\n",
    "comment_judgement(comms_df[:5])\n",
    "# comms_df[:5].merge(comment_judgement(comms_df[:5]), left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03720abc-5402-49bb-91de-73c19874f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all comments and pick out their judgement tags for ease of use later\n",
    "# comms_df = comms_df.merge(comment_judgement(comms_df), left_on='id', right_on='id')\n",
    "# comms_df.to_csv(f'backup_comms_df.csv', index=False)\n",
    "\n",
    "comms_df = pd.read_csv(f'backup_comms_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fb684-ba07-4660-bbba-38b46b04a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final post judgement based on top-scoring comment with a judgement\n",
    "def tag_post_judgements(posts_df, comms_df):\n",
    "    # VAL1: Return mapping between t3-less post ID to several attributes related to the judgements of a post\n",
    "    # ATTR: Final judgement tag: determined by top-scoring comment with a judgement tag\n",
    "    # ATTR: Controversialness metric: based on what r/AITAFiltered uses, the ratio between judgements of (ESH/YTA) : (NAH/NTA)\n",
    "    # Let X be the number of ESH/YTA (\"you're an asshole\") judgements\n",
    "    # Let Y be the number of NAH/NTA (\"you're not an asshole\") judgements\n",
    "    # Then X/(X+Y)=Z is the fraction of all decided (non-SHP and non-INFO) judgements that call the OP an asshole\n",
    "    # Then calculating 1+(-2)(|Z-0.5|) is a linear metric in the range [0,1], where 0 means full consensus and 1 means 50-50 judgement split\n",
    "    # If there are no judgements, then the controversialness is 0 by default\n",
    "    # ATTR: Judgement distribution: a tuple containing counts for (NTA, YTA, NAH, ESH, INFO) judgements\n",
    "    # VAL2: Return mapping between t3-less post ID with individual usernames, the judgements they left on that post, and the comment score they had for that judgement\n",
    "    tags = {'id':[], 'final_judgement':[], 'controversialness':[], 'controversialness_distrib':[]}\n",
    "    userdistrib = {'id':[], 'judgement_username':[], 'judgement_decision':[], 'judgement_score':[], 'judgement_correct':[]}\n",
    "    for _, post in posts_df.iterrows():\n",
    "        post_id = post['id']\n",
    "        tags['id'].append(post_id)\n",
    "        # get the judgement\n",
    "        judgements = comms_df[comms_df['link_id']==f't3_{post_id}']\n",
    "        # Filter out comments from bots, OP\n",
    "        judgements = judgements[judgements['author'] != post['author']]\n",
    "        judgements = judgements[~ judgements['author'].isin(restricted_users_list)]\n",
    "        if len(judgements)==0:\n",
    "            tags['final_judgement'].append(None)\n",
    "            tags['controversialness'].append(0)\n",
    "            tags['controversialness_distrib'].append( (0, 0, 0, 0, 0) )\n",
    "            continue\n",
    "        # Get the judgement tags for all relevant comments if they're not already processed\n",
    "        if 'judgement_tag' not in judgements:\n",
    "            judgements = judgements.merge(comment_judgement(judgements), left_on='id', right_on='id')\n",
    "        # Filter out comments without any judgement tag\n",
    "        judgements = judgements[judgements['judgement_tag'].apply(lambda x: str(x).upper()==x)]\n",
    "        if len(judgements)==0:\n",
    "            tags['final_judgement'].append(None)\n",
    "            tags['controversialness'].append(0)\n",
    "            tags['controversialness_distrib'].append( (0, 0, 0, 0, 0) )\n",
    "            continue\n",
    "        # Sort comments by score, descending. If there are tied scores, prioritize the one posted earlier\n",
    "        judgements = judgements.sort_values(by=['score', 'created_utc'], ascending=[False, True])\n",
    "        post_final_judgement = judgements.iloc[0]['judgement_tag']\n",
    "        # Save final judgement attributes\n",
    "        tags['final_judgement'].append(post_final_judgement)\n",
    "        # Read through each judgement and collect user mapping, indiv judgement type counts\n",
    "        users_parsed = set()\n",
    "        judgement_counts = {'NTA':0, 'YTA':0, 'NAH':0, 'ESH':0, 'INFO':0}\n",
    "        for _, x in judgements.iterrows():\n",
    "            # get user mapping\n",
    "            username = x['author']\n",
    "            judgement = x['judgement_tag']\n",
    "            if username not in users_parsed:\n",
    "                userdistrib['id'].append(post_id)\n",
    "                userdistrib['judgement_username'].append(username)\n",
    "                userdistrib['judgement_decision'].append(judgement)\n",
    "                userdistrib['judgement_score'].append(x['score'])\n",
    "                userdistrib['judgement_correct'].append(1 if (judgement==post_final_judgement) else 0)\n",
    "                users_parsed.add(username)\n",
    "            # get the judgement type\n",
    "            if judgement in judgement_counts:\n",
    "                judgement_counts[judgement] += 1\n",
    "        # Calculate controversialness metric\n",
    "        controversialness = (judgement_counts['ESH']+judgement_counts['YTA'])/(judgement_counts['ESH']+judgement_counts['YTA']+judgement_counts['NAH']+judgement_counts['NTA'])\n",
    "        controversialness = abs(controversialness - 0.5)\n",
    "        controversialness = controversialness * -2\n",
    "        controversialness = controversialness + 1\n",
    "        # Save judgement distribution attributes\n",
    "        tags['controversialness'].append(controversialness)\n",
    "        tags['controversialness_distrib'].append((\n",
    "            judgement_counts['NTA'], \n",
    "            judgement_counts['YTA'], \n",
    "            judgement_counts['NAH'], \n",
    "            judgement_counts['ESH'], \n",
    "            judgement_counts['INFO']))\n",
    "    return pd.DataFrame(tags), pd.DataFrame(userdistrib)\n",
    "\n",
    "temp_a, temp_b = tag_post_judgements(posts_df[:5], comms_df)\n",
    "temp_a\n",
    "temp_b[:5]\n",
    "# posts_df[:5].merge(tag_post_judgements(posts_df[:5], comms_df), left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb888c5-39ea-4b44-a0d8-e1fbb1f3a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement relationship between user and final judgement\n",
    "# TODO implement sentiment difference between a pair of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296261c3-9d2e-47ac-8ed9-fed1442c7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "gAll = {}\n",
    "\n",
    "for _, post in posts_df.iterrows():\n",
    "    g = nx.DiGraph()\n",
    "    post_id = post['id']\n",
    "    userResponders = {}\n",
    "    for _, comment in comms_df[comms_df['link_id']==f't3_{post_id}'].iterrows():\n",
    "        parentID = comment['parent_id']\n",
    "        currentID = 't1_'+comment['id']\n",
    "        author = comment['author']\n",
    "        g.add_edge(parentID, currentID)\n",
    "        g.nodes[currentID]['author'] = author\n",
    "        if author not in userResponders:\n",
    "            userResponders[author] = []\n",
    "        userResponders[author].append(currentID)    \n",
    "    gAll[f't3_{post_id}'] = {\n",
    "        'post_graph': g,\n",
    "        'user_op': post['author'],\n",
    "        'user_responders': userResponders,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de806522-ec06-42f3-a719-04883c12ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_max = ''\n",
    "maxcount = 0\n",
    "for _, post in posts_df.iloc[:100].iterrows():\n",
    "    commcount = post['num_comments']\n",
    "    if commcount > maxcount:\n",
    "        maxcount = commcount\n",
    "        temp_max = 't3_'+post['id']\n",
    "print(temp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010943ef-0248-4fad-8926-d10aaf3210bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the graph building\n",
    "postID = 't3_9zigtr' # list(gAll.keys())[9999]\n",
    "postG = gAll[postID]['post_graph']\n",
    "# print(postG.nodes.data())\n",
    "nx.draw_kamada_kawai(\n",
    "    postG, \n",
    "#     node_color=[\n",
    "#         d['comment_author'] if 'comment_author' in d else gAll[postID]['user_op']\n",
    "#         for (n,d) in postG.nodes.data()\n",
    "#     ]\n",
    ")\n",
    "print(postID)\n",
    "print(gAll[postID]['user_op'])\n",
    "print(gAll[postID]['user_responders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2196027-4431-4607-b177-bbfd68000d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many branches a user has touched\n",
    "# path metric:\n",
    "# count of how many unique paths are needed for all of the user's posts to be reached\n",
    "def branch_count(username, postID):\n",
    "    # retrieve graph we are working with\n",
    "    g = gAll[postID]['post_graph']\n",
    "    # calculate path to each of the poster's comments\n",
    "    commentPaths = {}\n",
    "    for cID in gAll[postID]['user_responders'][username]:\n",
    "        try:\n",
    "            commentPaths[cID] = nx.shortest_path(g, postID, cID)\n",
    "        except:\n",
    "            continue\n",
    "    # starting from longest path, remove all comments along that path (since theyre not unique)\n",
    "    pathCount = 0\n",
    "    while len(commentPaths) > 0:\n",
    "#         print(commentPaths)\n",
    "        deepestCID = sorted(\n",
    "            [(k, len(commentPaths[k])) for k in commentPaths],\n",
    "            key=(lambda x: x[1]),\n",
    "        )\n",
    "        deepestPath = commentPaths[deepestCID[-1][0]]\n",
    "        for cID in deepestPath:\n",
    "            commentPaths.pop(cID, None)\n",
    "        pathCount += 1\n",
    "    return pathCount\n",
    "\n",
    "username = \"Killairmanable\"\n",
    "postID = \"t3_9zigtr\"\n",
    "print(branch_count(username, postID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6dbec-e675-443c-8a56-ab9442873a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "# higher = more breadth\n",
    "def branchiness(username, postID, getGraph=False):\n",
    "    # retrieve graph we are working with\n",
    "    g = gAll[postID]['post_graph']\n",
    "    # calculate path to each of the poster's comments\n",
    "    commentPaths = {}\n",
    "    for cID in gAll[postID]['user_responders'][username]:\n",
    "        try:\n",
    "            commentPaths[cID] = nx.shortest_path(g, postID, cID)\n",
    "        finally:\n",
    "            # print(f'{cID} nonexistent comment?')\n",
    "            continue\n",
    "    # starting from shortest path, build out tree of direct dependencies\n",
    "    gPath = nx.DiGraph()\n",
    "    nodesAdded = [postID]\n",
    "    while len(commentPaths) > 0:\n",
    "#         print(commentPaths)\n",
    "        closestCID = sorted(\n",
    "            [(k, len(commentPaths[k])) for k in commentPaths],\n",
    "            key=(lambda x: x[1]),\n",
    "        )\n",
    "        closestPath = commentPaths[closestCID[0][0]]\n",
    "        closestCID = closestPath[-1]\n",
    "        topLevel = True\n",
    "        for n in nodesAdded:\n",
    "            if nx.has_path(g, n, closestCID):\n",
    "                topLevel = False\n",
    "                gPath.add_edge(n, closestCID)\n",
    "                nodesAdded = [closestCID]+nodesAdded\n",
    "                break\n",
    "        if topLevel:\n",
    "            gPath.add_edge(postID, closestCID)\n",
    "            nodesAdded = [closestCID]+nodesAdded\n",
    "        commentPaths.pop(closestCID, None)\n",
    "    # calculate average degree\n",
    "    degrees = [d for (n,d) in gPath.out_degree() if d!=0]\n",
    "    if len(degrees)==0:\n",
    "        # there was some hole in the graph between ALL of a user's comments and the main post...\n",
    "        return None, None\n",
    "    degreeAvg = sum(degrees)/len(degrees)\n",
    "    degreeMed = statistics.median(degrees)\n",
    "    if getGraph:\n",
    "        return degreeAvg, gPath\n",
    "    return degreeAvg, degreeMed\n",
    "\n",
    "username = \"Killairmanable\"\n",
    "postID = \"t3_9zigtr\"\n",
    "print(branchiness(username, postID))\n",
    "\n",
    "# Sanity check this metric?\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = []\n",
    "for postID in gAll:\n",
    "    for uname in gAll[postID]['user_responders']:\n",
    "        if uname!=gAll[postID]['user_op'] and uname not in re:\n",
    "            brtuple = branchiness(uname, postID)\n",
    "            if brtuple[0] is not None:\n",
    "                t.append((\n",
    "                    len(gAll[postID]['user_responders'][uname]),\n",
    "                    brtuple,\n",
    "                ))\n",
    "\n",
    "tNext = []\n",
    "for l in set([i[0] for i in t]):\n",
    "    v = [i[1][0] for i in t if i[0]==l]\n",
    "    v = sum(v)/len(v)\n",
    "    tNext.append( (l, v) )\n",
    "plt.scatter(\n",
    "    [x for (x, _) in tNext], \n",
    "    [y for (_, y) in tNext], \n",
    ")\n",
    "plt.xlabel('# of comments')\n",
    "plt.ylabel('avg(avg degree of indiv comment tree)')\n",
    "plt.show()\n",
    "\n",
    "tNext = []\n",
    "for l in set([i[0] for i in t]):\n",
    "    v = [i[1][1] for i in t if i[0]==l]\n",
    "    v = sum(v)/len(v)\n",
    "    tNext.append( (l, v) )\n",
    "plt.scatter(\n",
    "    [x for (x, _) in tNext], \n",
    "    [y for (_, y) in tNext], \n",
    ")\n",
    "plt.xlabel('# of comments')\n",
    "plt.ylabel('avg(med degree of indiv comment tree)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b64578-9df3-4c1e-b722-2afd89ee1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get branch count for responders\n",
    "distribCount = {} # map from [number of branches]: [users who have had that number]\n",
    "userCount = {}    # map from [usernames]: [branch distribution they've done]\n",
    "userBCount = {}    # map from [usernames]: [branchiness distribution they've done]\n",
    "for postID in gAll.keys():\n",
    "    for u in gAll[postID]['user_responders']:\n",
    "        if u!=gAll[postID]['user_op'] and u not in restricted_users_list:\n",
    "            count = branch_count(u, postID)\n",
    "            if count!=0:\n",
    "                ctrlcount = branchiness(u, postID)\n",
    "                if count not in distribCount:\n",
    "                    distribCount[count] = []\n",
    "                distribCount[count].append(u)\n",
    "                if u not in userCount:\n",
    "                    userCount[u] = []\n",
    "                userCount[u].append(count)\n",
    "                if u not in userBCount:\n",
    "                    userBCount[u] = []\n",
    "                userBCount[u].append(ctrlcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc23c86-3270-4d32-987b-294d0760e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = [(k, len(set(distribCount[k])), set(distribCount[k])) for k in distribCount.keys()]\n",
    "t = [(a,b,c) for (a,b,c) in t if b!=0]\n",
    "t = sorted(t, key=lambda x: x[0])\n",
    "print([(a,b) for (a,b,c) in t])\n",
    "\n",
    "plt.scatter(\n",
    "    [b for (b, _, _) in t], \n",
    "    [math.log(fq) for (_, fq, _) in t], \n",
    ")\n",
    "plt.xlabel('# of branches (X)')\n",
    "plt.ylabel('log(# of users who touched X branches)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da59fa-633e-481c-b791-3589dd4a7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = [(k, sum(userCount[k]), len(userCount[k]), max(userCount[k])) for k in userCount.keys()]\n",
    "t = sorted(t, key=lambda x: x[2], reverse=True)\n",
    "print('(username, avg branches/post, max branches/post, #posts touched)')\n",
    "for i in ([(a,b/c,d,c) for (a,b,c,d) in t])[:10]:\n",
    "    print(i)\n",
    "\n",
    "plt.scatter(\n",
    "    [pc for (_, _, pc, _) in t], \n",
    "    [math.log(sumB/numB) for (_, sumB, numB, _) in t],\n",
    "    alpha=0.05\n",
    ")\n",
    "plt.xlabel('# of posts commented on')\n",
    "plt.ylabel('log(Average number of branches touched)')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(\n",
    "    [pc for (_, _, pc, _) in t], \n",
    "    [maxB for (_, _, _, maxB) in t],\n",
    "    alpha=0.05\n",
    ")\n",
    "plt.xlabel('# of posts commented on')\n",
    "plt.ylabel('Max number of branches touched')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb140d36-a167-48c6-b4e5-5d2f2dcb2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = [(k, sum([e[0] for e in userBCount[k]]), len([e[0] for e in userBCount[k]]), max([e[0] for e in userBCount[k]])) for k in userBCount.keys()]\n",
    "t = sorted(t, key=lambda x: x[2], reverse=True)\n",
    "print('(username, avg branchiness/post, max branchiness/post, #posts touched)')\n",
    "for i in ([(a,b/c,d,c) for (a,b,c,d) in t])[:10]:\n",
    "    print(i)\n",
    "\n",
    "plt.scatter(\n",
    "    [pc for (_, _, pc, _) in t], \n",
    "    [math.log(sumB/numB) for (_, sumB, numB, _) in t],\n",
    "    alpha=0.05\n",
    ")\n",
    "plt.xlabel('# of posts commented on')\n",
    "plt.ylabel('log(Average branchiness)')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(\n",
    "    [pc for (_, _, pc, _) in t], \n",
    "    [maxB for (_, _, _, maxB) in t],\n",
    "    alpha=0.05\n",
    ")\n",
    "plt.xlabel('# of posts commented on')\n",
    "plt.ylabel('Max branchiness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86545764-df32-474e-80ee-9d0d8f2bafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = [[e[0] for e in userBCount[k]] for k in userBCount.keys()]\n",
    "t = [i for sl in t for i in sl]\n",
    "plt.hist(t, bins=100)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Branchiness (per user, per post)')\n",
    "plt.show()\n",
    "\n",
    "t = [[e[0] for e in userBCount[k]] for k in userBCount.keys()]\n",
    "t = [i for sl in t for i in sl]\n",
    "t = [i for i in t if i<5]\n",
    "plt.hist(t, bins=100)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Branchiness (per user, per post) range [0,5)')\n",
    "plt.show()\n",
    "\n",
    "t = [[e[0] for e in userBCount[k]] for k in userBCount.keys()]\n",
    "t = [i for sl in t for i in sl]\n",
    "t = [i for i in t if i<5 and i>1]\n",
    "plt.hist(t, bins=100)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Branchiness (per user, per post) range (1,5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b026606-db58-4820-88d4-6e58ffca7143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132d23c-3247-4e8d-a23c-524796b704c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
