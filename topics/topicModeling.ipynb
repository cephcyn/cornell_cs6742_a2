{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a44789",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "Purpose: Identify topics within the dataset with the LDA model\n",
    "<br>Note: Cleaning isn't perfect results show there are distinguishable topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "497daf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import math\n",
    "import random\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95c10ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables used in cleaning the posts\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "my_stopwords.extend(['t','v','don','didn','gt','like','got','asshole','i','im',\"'t\"])\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "Apos_dict={\"'s\":\" is\",\"n't\":\" not\",\"'m\":\" am\",\"'ll\":\" will\",\n",
    "           \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b532a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleans each post\n",
    "def clean_post(post, bigrams=False):\n",
    "\n",
    "    #removing contractions\n",
    "    for key,value in Apos_dict.items():\n",
    "        if key in post:\n",
    "            post = post.replace(key,value)\n",
    "    post = post.lower() #lowercase\n",
    "    post = post.replace(\"'\",\"\") #removing apostraphe\n",
    "    post = re.sub('[' + my_punctuation + ']+', ' ', post) # strip punctuation\n",
    "    post = re.sub('\\s+', ' ', post) #remove double spacing\n",
    "    post = re.sub('([0-9]+)', '', post) # remove numbers\n",
    "    post_token_list = [word for word in post.split(' ')\n",
    "                        if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "    post_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in post_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        post_token_list = post_token_list+[post_token_list[i]+'_'+post_token_list[i+1]\n",
    "                                            for i in range(len(post_token_list)-1)]\n",
    "    post = ' '.join(post_token_list)\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3341d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes blank lines, deleted posts, or removed posts\n",
    "def csvClean(infile):\n",
    "    redditData = pd.read_csv(infile)\n",
    "    data = redditData['selftext']\n",
    "    data  = data.replace('[deleted]',np.nan)\n",
    "    data= data.replace('[removed]', np.nan)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "306e45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dataframe with the topics & weights\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c16f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
      "0            ’t         15376.0           mom          3999.2            ’t   \n",
      "1             ’         10871.2          year          3607.9             ’   \n",
      "2             i         10231.4          time          3357.3             i   \n",
      "3            ’m          6578.2            go          3175.9            ’m   \n",
      "4             ”          4818.1          want          3146.8            go   \n",
      "5           don          4478.0         would          3031.9          time   \n",
      "6            it          3489.7        famili          3003.8           get   \n",
      "7          didn          3338.3        sister          2784.4          want   \n",
      "8            ’v          2905.9           dad          2676.3           don   \n",
      "9           she          2341.1           get          2548.7            it   \n",
      "\n",
      "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \\\n",
      "0          5947.9          work          7190.8          room          2341.0   \n",
      "1          3589.6          time          3660.6           get          2162.5   \n",
      "2          3524.3           get          3335.9         would          1964.0   \n",
      "3          2280.7         would          3049.1           use          1681.5   \n",
      "4          1738.8           day          2965.6           one          1643.5   \n",
      "5          1709.5           ask          2267.0           ask          1549.2   \n",
      "6          1566.3            go          2238.4          back          1358.3   \n",
      "7          1537.5           job          2228.9          time          1333.5   \n",
      "8          1516.6          week          1999.1       roommat          1288.7   \n",
      "9          1251.5          hour          1881.8          live          1216.7   \n",
      "\n",
      "  Topic 5 words Topic 5 weights Topic 6 words Topic 6 weights Topic 7 words  \\\n",
      "0        friend          6015.8           dog          3417.3         money   \n",
      "1            go          4905.3           car          2546.3          want   \n",
      "2          said          4137.4           get          1679.0           pay   \n",
      "3           say          3879.4           cat          1372.6         would   \n",
      "4          want          3764.5          walk          1215.3          year   \n",
      "5           ask          3395.8         drive          1197.3        famili   \n",
      "6           get          3179.3           amp          1179.4           get   \n",
      "7         would          2765.4            go          1033.4            go   \n",
      "8          told          2701.4          back           961.4        parent   \n",
      "9          play          2340.2          home           916.2          make   \n",
      "\n",
      "  Topic 7 weights Topic 8 words Topic 8 weights Topic 9 words Topic 9 weights  \n",
      "0          3636.4        friend         11997.4           kid          1882.6  \n",
      "1          3075.4          feel          6064.5          said          1595.3  \n",
      "2          2750.9          talk          5752.4        school          1547.1  \n",
      "3          2640.0         would          5567.3           say          1039.3  \n",
      "4          2592.7          want          4986.9           get          1028.3  \n",
      "5          2463.9          time          4449.7          call           959.0  \n",
      "6          2254.5        realli          4404.1          back           948.4  \n",
      "7          1692.9         thing          3884.3           one           935.9  \n",
      "8          1504.7          know          3817.5         class           933.0  \n",
      "9          1445.4          year          3435.9         start           919.7  \n"
     ]
    }
   ],
   "source": [
    "#Removing blank lines, removed posts, or deleted posts\n",
    "postData = csvClean('2018_posts.csv')\n",
    "postData = postData.to_frame()\n",
    "\n",
    "#Cleaning the remaining posts\n",
    "postData['clean_posts'] = postData.selftext.apply(clean_post)\n",
    "\n",
    "#Creating vector\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "#Transforming vector\n",
    "tf = vectorizer.fit_transform(postData['clean_posts'].values.astype('U')).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#Creating model\n",
    "number_of_topics = 10\n",
    "no_top_words = 10\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "model.fit(tf)\n",
    "topicData = display_topics(model, tf_feature_names, no_top_words)\n",
    "print(topicData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6dc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
